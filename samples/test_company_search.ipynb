{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sentence_transformers import CrossEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_name = 'all-mpnet-base-v2' #all-mpnet-base-v2 #all-MiniLM-L6-v2\n",
    "embedding_model = SentenceTransformer(embedding_model_name)\n",
    "embedding_model.save(embedding_model_name)\n",
    "\n",
    "cross_encoder_model_name = 'cross-encoder/ms-marco-MiniLM-L-6-v2' # cross-encoder/stsb-roberta-base #cross-encoder/ms-marco-MiniLM-L-6-v2 \n",
    "cross_encoder_model = CrossEncoder(cross_encoder_model_name) \n",
    "cross_encoder_model.save(cross_encoder_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_filename = f'{embedding_model_name}_name.pkl'\n",
    "col_to_embed = \"Company_name\" #Company_name #Company_name_industry\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "company_names_path = os.path.join(parent_dir, \"all_company_names_final.csv\")\n",
    "pickle_filepath = os.path.join(parent_dir, pickle_filename)\n",
    "\n",
    "df = pd.read_csv(company_names_path)\n",
    "\n",
    "if os.path.exists(pickle_filepath ):\n",
    "    with open(pickle_filepath , \"rb\") as fIn:\n",
    "       cache_data = pickle.load(fIn)\n",
    "       company_names = cache_data['company_names']\n",
    "       company_names_embeddings = cache_data['company_names_embeddings']\n",
    "       u3_nums = cache_data['u3_nums']\n",
    "\n",
    "else:\n",
    "\n",
    "    company_names = df['Company_name'].values.tolist()\n",
    "    company_names_for_embedding = df[col_to_embed].values.tolist()\n",
    "    u3_nums = df['u3_num'].values.tolist()\n",
    "    company_names_embeddings = embedding_model.encode(company_names_for_embedding, show_progress_bar=True, convert_to_tensor=True)\n",
    "\n",
    "    with open(pickle_filepath, \"wb\") as fOut:\n",
    "        pickle.dump({'company_names': company_names, 'company_names_embeddings': company_names_embeddings, 'u3_nums': u3_nums}, \n",
    "                    fOut\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_top_k_most_similar(query, top_k=100):\n",
    "    query_embedding = embedding_model.encode(query, convert_to_tensor=False)\n",
    "    hits = util.semantic_search(query_embedding, company_names_embeddings, top_k=top_k)\n",
    "    hits = hits[0]  \n",
    "    candidates = [company_names[hit['corpus_id']] for hit in hits]\n",
    "    return hits, candidates\n",
    "\n",
    "def re_rank(query, hits, candidates):\n",
    "    sentence_pairs = [[query, candidate] for hit,candidate in zip(hits, candidates)]\n",
    "    ce_scores = cross_encoder_model.predict(sentence_pairs)\n",
    "    for ce_score, hit in zip(ce_scores, hits):\n",
    "        hit['cross-encoder_score'] = ce_score\n",
    "\n",
    "    # Sort by score, highest score at the top\n",
    "    hits = sorted(hits, key=lambda x: x['cross-encoder_score'], reverse=True)\n",
    "    candidates_reranked = [company_names[hit['corpus_id']] for hit in hits]\n",
    "    return hits, candidates_reranked\n",
    "\n",
    "def get_match(query, thresh_cross_encoder_score=0):\n",
    "\n",
    "    hits, candidates = return_top_k_most_similar(query, top_k=100)\n",
    "    hits, candidates_reranked = re_rank(query, hits, candidates)\n",
    "\n",
    "    company_found = None\n",
    "    for hit in hits:\n",
    "\n",
    "        candidate = company_names[hit['corpus_id']]\n",
    "        if float(hit['cross-encoder_score']) > thresh_cross_encoder_score :\n",
    "            company_found = candidate\n",
    "        else:\n",
    "            pass\n",
    "        break\n",
    "    return company_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "\"General Electric (Conglomerate)\", 'Danaher (Medical Technology)'\n",
    "'Berkshire Hathaway - Insurance',  'Berkshire Hathaway (Insurance)', \n",
    "'Lee Enterprises (Media)', \"Jordan's (Retail)\", 'RC Willey (Retail)', \n",
    "'Berkshire Hathaway (Insurance)', 'Xilinx (Semiconductors)', \n",
    "'Caterpillar (Heavy Machinery)', 'Xerox (Technology)', \n",
    "'Samsonite (Luggage)', 'Netflix (Entertainment)', \n",
    "'Marvel (Entertainment)', 'Medicine of the Angels (Cannabis)', \n",
    "'Coda (Cannabis)', 'Intel (Semiconductors)', \n",
    "'Morgan Stanley (Investment Banking)', 'Nvidia (Semiconductors)',\n",
    "\"Pepsi (Food & Beverage)\", \"Pepsi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match: 'General Electric Co PLC' found for query: 'General Electric (Conglomerate)'\n",
      "No match found for query: 'Danaher Berkshire Hathaway - Insurance'\n",
      "match: 'Berkshire Hathaway Inc' found for query: 'Berkshire Hathaway (Insurance)'\n",
      "match: 'Lee Enterprises Inc' found for query: 'Lee Enterprises (Media)'\n",
      "match: 'Jordan American Holdings Inc' found for query: 'Jordan's (Retail)'\n",
      "match: 'RCL Retail Ltd' found for query: 'RC Willey (Retail)'\n",
      "match: 'Berkshire Hathaway Inc' found for query: 'Berkshire Hathaway (Insurance)'\n",
      "match: 'Xilinx Inc' found for query: 'Xilinx (Semiconductors)'\n",
      "match: 'Caterpillar Inc' found for query: 'Caterpillar (Heavy Machinery)'\n",
      "match: 'Xantrex Technology Inc' found for query: 'Xerox (Technology)'\n",
      "match: 'Samsonite LLC/OLD' found for query: 'Samsonite (Luggage)'\n",
      "match: 'Netflix Inc' found for query: 'Netflix (Entertainment)'\n",
      "match: 'Marvel Entertainment LLC' found for query: 'Marvel (Entertainment)'\n",
      "No match found for query: 'Medicine of the Angels '\n",
      "match: 'Coda Energy Inc' found for query: 'Coda (Cannabis)'\n",
      "match: 'Intel Corp' found for query: 'Intel '\n",
      "match: 'Morgan Stanley' found for query: 'Morgan Stanley (Investment Banking)'\n",
      "match: 'NVIDIA Corp' found for query: 'Nvidia (Semiconductors)'\n",
      "match: 'Pepsi Bottling Group Inc/The' found for query: 'Pepsi '\n",
      "match: 'Pepsi Bottling Group Inc/The' found for query: 'Pepsi'\n"
     ]
    }
   ],
   "source": [
    "# demo\n",
    "\n",
    "for query in queries:\n",
    "\n",
    "    match = get_match(query)\n",
    "    if match is None:\n",
    "        # remove industry and try to match again\n",
    "        query = re.sub(r\"(\\(.+\\))|\\[.+\\]\",'', query)\n",
    "        #print(query)\n",
    "        match = get_match(query) \n",
    "        if match is None:\n",
    "            print(f\"No match found for query: '{query}'\")\n",
    "        else:\n",
    "            print(f\"match: '{match}' found for query: '{query}'\")\n",
    "\n",
    "    else:\n",
    "        print(f\"match: '{match}' found for query: '{query}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = ['Amazon (in reference to a partnership)', 'Unilver (industries: personal care and household products)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match: 'Amazon.com Inc' found for query: 'Amazon '\n",
      "match: 'Uniliver Nepal Ltd' found for query: 'Unilver '\n"
     ]
    }
   ],
   "source": [
    "# demo\n",
    "\n",
    "for query in queries:\n",
    "\n",
    "    match = get_match(query)\n",
    "    if match is None:\n",
    "        # remove industry and try to match again\n",
    "        query = re.sub(r\"(\\(.+\\))|\\[.+\\]\",'', query)\n",
    "        #print(query)\n",
    "        match = get_match(query) \n",
    "        if match is None:\n",
    "            print(f\"No match found for query: '{query}'\")\n",
    "        else:\n",
    "            print(f\"match: '{match}' found for query: '{query}'\")\n",
    "\n",
    "    else:\n",
    "        print(f\"match: '{match}' found for query: '{query}'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dict_approach",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
